Лабораторная работа 2
===
Решение задачи классификации изображений из набора данных Oregon Wildlife с использованием нейронных сетей глубокого обучения и техники обучения Transfer Learning
----
### Для решения задачи классификации изображений Oregon Wildlife необходимо было обучить нейронную сеть, с начальным случайным приближением, EfficientNet-B0.
Размерность входного изображения, как и первой лабораторной работе, 224х224х3 и, как было сказано выше, использовалась нейронная сеть EfficientNet-B0:
```
inputs = tf.keras.Input(shape=(RESIZE_TO, RESIZE_TO, 3))
outputs = EfficientNetB0(include_top=True,weights=None, classes = NUM_CLASSES)(inputs)
```
В нашем случае используется параметр `weights` со значением `None`, что означает использование начального случайного приближения. Параметр `include_top=true` oзначает использование верхних слоев нейронной сети, отвечающих за классификацию изображений. Параметр `classes = NUM_CLASSES` отвечает за количество классов классифицированных изображений (в нашем случае количество классов = 20).

Графики обучения для задачи классификации изображений Oregon WildLife, используя случайное начальное приближение:
----
*синяя ломаная линия - на валидации*

*оранжевая ломаная линия - на обучении*

**График метрики точности:**

![1](https://user-images.githubusercontent.com/59210216/111230601-f1cc1700-85f8-11eb-8f42-d3ce70cec56e.jpg)


**График функции потерь:**

![2](https://user-images.githubusercontent.com/59210216/111230610-f4c70780-85f8-11eb-899b-1b96f373cedd.jpg)

Анализ полученных результатов:
-------
Анализируя полученные диаграммы можно заметить, что, на графике функции метрики точности, ломаная на валидации начала линейно возрастать, по отношению к графику функции потерь. Однако, если рассмотреть ломаную на обучении, то на графике функции потерь данная линия сильно убавила свои значения, по отношению к графику метрики точности. Также хочется отметить, что точность как на тренировочном, так и на валидационном наборе данных очень низкая (в максимальной точке достикается лишь 13%). Все это говорит о переобучение тестируемой модели, что может быть вызвано тем, что наш датасет слишком мал для начальных случайных приближений.

### С использованием примера, описываемого выше, и техники обучения Transfer Learning обучить нейроннуюсеть EfficientNet-B0, предобученную на базе изображений imagenet, для решения задачи классификации изображений Oregon WildLife:
**Transfer Learning** – это подраздел машинного обучения, целью которого является применение знаний, полученные из одной задачи, к другой целевой задаче. Существует множество решений, который могут помочь Data Scientist’у применить его к своей проблеме, поэтому нет необходимости изобретать велосипед. В нашем случае мы используем уже переобученные веса на базе изображенией ImageNet и получаем следующий вид нейронной сети:
 
* Входное изображение 224х224х3
```
  inputs = tf.keras.Input(shape=(RESIZE_TO, RESIZE_TO, 3)) 
```
* Нейронная сеть `EfficientNetB0`, `include_top = False` - отключаем верхний слой нейронов, потому что используем свой классификатор, `pooling='avg'` - выход модели будет представлять собой 2D-тензор, `weights='imagenet'` - используем предобученные веса.
```
  model = EfficientNetB0(include_top=False, input_tensor=inputs, pooling='avg', weights='imagenet')(inputs) 
```
* Заморозка сверточной базы
```
  model.trainable = False
  outputs = tf.keras.layers.Dense(NUM_CLASSES,activation=tf.keras.activations.softmax)(model)
  return tf.keras.Model(inputs=inputs, outputs=outputs)
```

Графики обучения для задачи классификации изображений Oregon WildLife, предобученную на базе изображений imagenet:
----
*синяя ломаная линия - на валидации*

*оранжевая ломаная линия - на обучении*

**График метрики точности:**

![5](https://user-images.githubusercontent.com/59210216/111324394-ccccb800-867b-11eb-940c-268e646453cc.jpg)

**График функции потерь:**

![6](https://user-images.githubusercontent.com/59210216/111324439-d524f300-867b-11eb-9847-0c48b8f4c25d.jpg)

Анализ полученных результатов:
-------
Анализируя полученные диаграммы можно увидеть, что, на графике метрики точности, обе ломаные - и ломаная на валидации, и ломаная на обучении - стремятся вверх. Обратная ситуации наблюдается на графике функции потерь.   
В данной задаче хотелось бы отметить, что результаты предобученной нейронной сети намного лучше, по сравнению с предыдущей задачей, ведь в данном случае метрика точности, в конце обучения, составляет 91%, чему и поспособствовала технология, изученная в рамках лабораторной работы, Transfer Learning.


